{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Внимание!!! Важно, что бы файлы с данными и исполняемый файл находились в одной папке, \n",
    "# тогда пути к тестовым и тренировочным наборам будут содержать только имена файлов.\n",
    "# \n",
    "# В пути к тренировочным и тестовым данным запрежается использовать абсалютную адресацию, \n",
    "# то есть адресацию, в которой присутствуют имена папок. Путь должен содержать только имя файла.\n",
    "#\n",
    "# Напоминание: под моделью машинного обучения понимаются все действия с исходными данными, \n",
    "# которые необходимо произвести, что бы сопоставить признаки целевому значению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 1 (библиотеки)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок в области 1 выполняется преподавателем\n",
    "# \n",
    "# данный блок предназначен только для подключения необходимых библиотек\n",
    "# запрещается подключать библиотеки в других блоках\n",
    "#\n",
    "# установка дополнительных библиотек размещается прямо здесь (обязательно закоментированы)\n",
    "#\n",
    "# pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # импорт IterativeImputer\n",
    "\n",
    "# Процессинг\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder, TargetEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PolynomialFeatures, QuantileTransformer, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "\n",
    "# CT\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Moдельки\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Meтрики\n",
    "from sklearn.metrics import mean_absolute_percentage_error, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "# стырил из пар \n",
    "import category_encoders as ce\n",
    "\n",
    "# убрать варнинги\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Область работы 2 (выполнение лучшей модели)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данный блок(и) в области 2 выполняется преподавателем\n",
    "#\n",
    "# В области находится одна, единственная, итоговая модель машинного обучения с однозначными, \n",
    "# зафиксированными параметрами\n",
    "#\n",
    "# В данной области категорически запрещается искать, выбирать, улучшать, оптимизировать, \n",
    "# тюниговать и т.д. модель машинного обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к тренировочному набору\n",
    "path_train = 'train.csv' # содержит только имя файла, без имен папок\n",
    "# Путь к тестовому набору\n",
    "path_test  = 'test.csv' # содержит только имя файла, без имен папок\n",
    "\n",
    "df = pd.read_csv(path_train)\n",
    "X_test = pd.read_csv(path_test)\n",
    "\n",
    "# Предобработка данных \n",
    "# 4 значения\n",
    "df = df[(df['table'] >= 40) & (df['table'] <= 80)]\n",
    "df = df[(df['depth'] >= 45) & (df['depth'] <= 75)]\n",
    "# 14 Нул значений\n",
    "df = df.drop(df[df[\"x\"]==0].index)\n",
    "df = df.drop(df[df[\"y\"]==0].index)\n",
    "df = df.drop(df[df[\"z\"]==0].index)\n",
    "# 78 дубликатов\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df = df[(df['x'] >= 2) & (df['x'] <= 11)]\n",
    "df = df[(df['y'] >= 2) & (df['y'] <= 11)]\n",
    "df = df[(df['z'] >= 2) & (df['z'] <= 7)]\n",
    "\n",
    "# Доработка данных\n",
    "X = df.drop(['price'], axis=1)\n",
    "y = df['price']                 \n",
    "\n",
    "# Всемогущий препроцессинг \n",
    "\n",
    "# Порядок признаков важен \n",
    "num_features = ['carat', 'depth', 'table']\n",
    "axis_features = ['x', 'y', 'z']\n",
    "clarity_map = [['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']]\n",
    "color_map = [['J', 'I', 'H', 'G', 'F', 'E', 'D']]\n",
    "cut_map = [['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']]\n",
    "\n",
    "\n",
    "# Числовые признаки\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler())  # Применение MinMaxScaler, ткв GridSearchCV\n",
    "])\n",
    "\n",
    "clarity_pipeline = Pipeline(steps=[\n",
    "    ('ce', OrdinalEncoder(categories=clarity_map)),  \n",
    "    ('scaler', PowerTransformer())\n",
    "])\n",
    "\n",
    "\n",
    "color_pipeline = Pipeline(steps=[\n",
    "    ('ce', OrdinalEncoder(categories=color_map)),  \n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cut_pipeline = Pipeline(steps=[\n",
    "    ('ce', OrdinalEncoder(categories=cut_map)),  \n",
    "    ('scaler', MinMaxScaler())  \n",
    "])\n",
    "\n",
    "axis_pipeline = Pipeline(steps=[\n",
    "    ('imputer', IterativeImputer(max_iter=20)),  \n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)), \n",
    "    ('scaler', StandardScaler())  \n",
    "])\n",
    "\n",
    "CT = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipeline, num_features),\n",
    "        (\"cut\", cut_pipeline, ['cut']),\n",
    "        (\"axis\", axis_pipeline, axis_features),\n",
    "        ('color', color_pipeline, ['color']),\n",
    "        ('clarity', clarity_pipeline, ['clarity'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ").set_output(transform='pandas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformedTargetRegressor(\n",
    "    regressor=Pipeline(steps=[\n",
    "        ('preprocessing', CT),  \n",
    "        ('estimator', KNeighborsRegressor(n_neighbors=11, p=5, weights='distance')  \n",
    "    ]),\n",
    "    transformer=StandardScaler()\n",
    ")\n",
    "\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок предсказания с использованием тестового набора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Наши любимые метрики (очень надеюсь, что не налажал тут) \n",
    "\n",
    "# X_test = pd.read_csv(path_test)\n",
    "# X = df.drop(['price'], axis=1)\n",
    "# y = df['price']   \n",
    "# y_test у Вас "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def irq_mse(y_test, y_pred):\n",
    "    delta = y_pred - y_test\n",
    "    Q25 = np.quantile(delta, 0.25)\n",
    "    Q75 = np.quantile(delta, 0.75)\n",
    "    irq = Q75 - Q25\n",
    "    mask = (delta < (Q25 - 1.5 * irq)) | (delta > (Q75 + 1.5 * irq))\n",
    "    if (mask.sum() == 0):\n",
    "        rez = 0\n",
    "    else:\n",
    "        rez = -sum((delta[mask]) ** 2) / mask.sum()\n",
    "    return rez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"IQR MSE: {irq_mse(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вектора предсказанных значений  y_predict полученый на основане тестового набора\n",
    "y_predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
